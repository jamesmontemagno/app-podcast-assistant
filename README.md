# Podcast Assistant - macOS App

> **âš ï¸ IMPORTANT:** Always open `PodcastAssistant.xcworkspace`, **NOT** `PodcastAssistant.xcodeproj`  
> Opening the `.xcodeproj` file directly will cause build errors: `Missing package product 'PodcastAssistantFeature'`

A SwiftUI macOS application for comprehensive podcast production management with Core Data persistence. Manage multiple podcasts, create episodes, convert transcripts to SRT format, and generate custom thumbnailsâ€”all in one integrated workflow.

## Features

### ðŸŽ™ï¸ Multi-Podcast Management
- Create and manage multiple podcasts with metadata and artwork
- Set default thumbnail settings per podcast (overlay, fonts, positioning)
- Organize episodes within each podcast
- Persistent local storage with Core Data
- CloudKit-ready schema for future iCloud sync

### ðŸ“ Transcript Conversion
- Import text transcript files per episode
- Automatically detect and convert multiple timestamp formats to SRT
- Export ready-to-upload SRT files for YouTube
- Speaker name preservation (Zencastr format)
- Intelligent timestamp calculation
- Episode-scoped storage (auto-saved to Core Data)

### ðŸŽ¨ Thumbnail Generation
- Episode-specific thumbnail creation with live preview
- Inherit default settings from parent podcast or customize per episode
- Load custom background images
- Optional overlay layer for branding
- Automatic episode number placement with customizable fonts and positioning
- Export as PNG or JPEG
- Generated thumbnails auto-saved with episode

## Requirements

- macOS 14.0 or later
- Xcode 16 or later (for building)

## Getting Started

### Quick Start (macOS)

The easiest way to open the project correctly:
```bash
./open-in-xcode.sh
```

Or manually:

### Opening the Project
1. Open `PodcastAssistant.xcworkspace` in Xcode (NOT the .xcodeproj file)
2. Wait for Swift Package Manager to resolve dependencies
3. Select the "PodcastAssistant" scheme
4. Build and run (âŒ˜R)

### Building from Command Line
```bash
# Build the app
xcodebuild -workspace PodcastAssistant.xcworkspace -scheme PodcastAssistant -configuration Debug
```

## Project Architecture

The app uses a **workspace + SPM package architecture** with Core Data for local persistence:

```
PodcastAssistant/
â”œâ”€â”€ PodcastAssistant.xcworkspace/              # Open this file in Xcode
â”œâ”€â”€ PodcastAssistant/                          # App shell (minimal)
â”‚   â””â”€â”€ PodcastAssistantApp.swift              # Entry point with Core Data injection
â”œâ”€â”€ PodcastAssistantPackage/                   # ðŸš€ Primary development area
â”‚   â””â”€â”€ Sources/PodcastAssistantFeature/
â”‚       â”œâ”€â”€ Models/                            # Core Data entities
â”‚       â”‚   â”œâ”€â”€ PodcastAssistant.xcdatamodeld  # Core Data model
â”‚       â”‚   â”œâ”€â”€ Podcast+CoreData*.swift        # Podcast entity
â”‚       â”‚   â””â”€â”€ Episode+CoreData*.swift        # Episode entity
â”‚       â”œâ”€â”€ Services/                          # Business logic
â”‚       â”‚   â”œâ”€â”€ PersistenceController.swift    # Core Data stack
â”‚       â”‚   â”œâ”€â”€ TranscriptConverter.swift      # SRT conversion
â”‚       â”‚   â”œâ”€â”€ ThumbnailGenerator.swift       # Image compositing
â”‚       â”‚   â””â”€â”€ ImageUtilities.swift           # Image processing
â”‚       â”œâ”€â”€ ViewModels/                        # Core Data-backed state
â”‚       â”‚   â”œâ”€â”€ TranscriptViewModel.swift      # Episode transcript state
â”‚       â”‚   â””â”€â”€ ThumbnailViewModel.swift       # Episode thumbnail state
â”‚       â””â”€â”€ Views/                             # SwiftUI views
â”‚           â”œâ”€â”€ ContentView.swift              # Master-detail navigation
â”‚           â”œâ”€â”€ PodcastFormView.swift          # Create/edit podcasts
â”‚           â”œâ”€â”€ EpisodeFormView.swift          # Create/edit episodes
â”‚           â”œâ”€â”€ TranscriptView.swift           # Transcript editor
â”‚           â””â”€â”€ ThumbnailView.swift            # Thumbnail generator
â”œâ”€â”€ docs/                                      # ðŸ“š Architecture documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md                        # System design & data flow
â”‚   â””â”€â”€ CORE_DATA.md                           # Core Data implementation guide
â””â”€â”€ Config/                                    # XCConfig build settings
```

### Navigation Flow

The app uses a three-column master-detail layout:

```
Podcast List  â†’  Episode List  â†’  Episode Detail (Transcript/Thumbnail)
     â†“                â†“                      â†“
  Sidebar        Middle Column          Detail Pane
```

**See [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) for complete architectural details.**

## Usage

### Getting Started

1. **Create a Podcast**
   - Click the "+" button in the podcast sidebar
   - Enter podcast name and optional description
   - Upload podcast artwork (resized to 1024x1024, JPEG compressed)
   - Configure default thumbnail settings (overlay, font, positioning)
   - These defaults will be copied to new episodes

2. **Create an Episode**
   - Select a podcast from the sidebar
   - Click the "+" button in the episode list
   - Enter episode title and number
   - Default thumbnail settings are automatically copied from the podcast

3. **Work on Episode Content**
   - Select an episode to view its detail pane
   - Switch between Transcript and Thumbnail tabs
   - All changes auto-save to Core Data

### Transcript Conversion

**Supported Input Formats:**

The converter automatically detects and handles multiple transcript formats:

**1. Zencastr Format** (automatically detected):
```
00:00.29
James
Welcome back everyone to Merge Conflict, your weekly developer podcast.

00:08.36
Frank
I am the other host. Hi, everyone.
```

**2. Time Range Format** (automatically detected):
```
00:00:00 - 00:00:05 Welcome to the podcast
00:00:05 - 00:00:10 Today we're talking about...
```

**Steps:**
1. Select an episode from the episode list
2. Click the "Transcript" tab in the detail pane
3. Import your text file or paste content directly
4. Click "Convert to SRT" (format is auto-detected)
5. Export the generated SRT file
6. Input and output are auto-saved with the episode

**Output Format:**
```srt
1
00:00:00,290 --> 00:00:05,290
James: Welcome back everyone to Merge Conflict, your weekly developer podcast.

2
00:00:08,360 --> 00:00:13,360
Frank: I am the other host. Hi, everyone.
```

### Thumbnail Generation

**Steps:**
1. Select an episode from the episode list
2. Click the "Thumbnail" tab in the detail pane
3. Select a background image (required) - auto-processed and saved
4. Optionally select an overlay image for branding
5. Episode number is pre-filled from episode data
6. Font and position settings are inherited from podcast defaults
7. Thumbnail generates automatically with live preview
8. Generated thumbnail auto-saves with the episode
9. Click "Export Thumbnail" to save as PNG/JPEG file

**Default Settings:**
- New episodes automatically copy font, overlay, and positioning from podcast defaults
- Customize per-episode if neededâ€”changes won't affect the podcast defaults

## Core Data & Persistence

### Data Model

**Podcast Entity:**
- Name, description, artwork
- Default thumbnail settings (overlay, font, positioning)
- One-to-many relationship with episodes (cascade delete)

**Episode Entity:**
- Title, episode number
- Transcript input text and SRT output text
- Thumbnail images (background, overlay, generated output)
- Font and positioning settings (copied from podcast defaults)
- Many-to-one relationship with podcast

**See [docs/CORE_DATA.md](docs/CORE_DATA.md) for complete Core Data implementation details.**

### Image Storage

Images are stored as binary data (BLOBs) in Core Data for simplicity and future iCloud compatibility:
- Automatically resized to max 1024x1024 pixels
- JPEG compressed at 0.8 quality
- External binary storage enabled for large files
- Typical size: 100-500KB per image

### iCloud Sync (Future)

The Core Data schema is CloudKit-ready. To enable iCloud sync in the future:
1. Change `NSPersistentContainer` â†’ `NSPersistentCloudKitContainer`
2. Add CloudKit entitlements
3. No data migration needed

**See detailed iCloud migration steps in [docs/CORE_DATA.md](docs/CORE_DATA.md).**

## Development Notes

### Code Organization
Most development happens in `PodcastAssistantPackage/Sources/PodcastAssistantFeature/` - organize your code as you prefer.

### Public API Requirements
Types exposed to the app target need `public` access:
```swift
public struct SettingsView: View {
    public init() {}
    
    public var body: some View {
        // Your view code
    }
}
```

### Adding Dependencies
Edit `PodcastAssistantPackage/Package.swift` to add SPM dependencies:
```swift
dependencies: [
    .package(url: "https://github.com/example/SomePackage", from: "1.0.0")
],
targets: [
    .target(
        name: "PodcastAssistantFeature",
        dependencies: ["SomePackage"]
    ),
]
```

### Test Structure
- **Unit Tests**: `PodcastAssistantPackage/Tests/PodcastAssistantFeatureTests/` (Swift Testing framework)
- **UI Tests**: `PodcastAssistantUITests/` (XCUITest framework)
- **Test Plan**: `PodcastAssistant.xctestplan` coordinates all tests

## Configuration

### XCConfig Build Settings
Build settings are managed through **XCConfig files** in `Config/`:
- `Config/Shared.xcconfig` - Common settings (bundle ID, versions, deployment target)
- `Config/Debug.xcconfig` - Debug-specific settings  
- `Config/Release.xcconfig` - Release-specific settings
- `Config/Tests.xcconfig` - Test-specific settings

### App Sandbox & Entitlements
The app is sandboxed by default with basic file access. Edit `PodcastAssistant/PodcastAssistant.entitlements` to add capabilities:
```xml
<key>com.apple.security.files.user-selected.read-write</key>
<true/>
<key>com.apple.security.network.client</key>
<true/>
<!-- Add other entitlements as needed -->
```

## macOS-Specific Features

### Window Management
Add multiple windows and settings panels:
```swift
@main
struct PodcastAssistantApp: App {
    var body: some Scene {
        WindowGroup {
            ContentView()
        }
        
        Settings {
            SettingsView()
        }
    }
}
```

### Asset Management
- **App-Level Assets**: `PodcastAssistant/Assets.xcassets/` (app icon with multiple sizes, accent color)
- **Feature Assets**: Add `Resources/` folder to SPM package if needed

### SPM Package Resources
To include assets in your feature package:
```swift
.target(
    name: "PodcastAssistantFeature",
    dependencies: [],
    resources: [.process("Resources")]
)
```

## Customization

### Adding New Fonts

The app supports two approaches for adding custom fonts:

#### Option 1: Runtime Font Loading (Recommended)
The app includes a built-in font loader that lets you add custom fonts at runtime without rebuilding:

1. Click the "Thumbnail" tab
2. Click "Load Custom Font" button
3. Select a `.ttf` or `.otf` font file
4. The font will be registered and added to the font picker automatically

**Advantages:**
- No code changes needed
- Fonts persist across app launches (saved in UserDefaults)
- Easy to add/test different fonts

#### Option 2: Bundling Fonts in the App
To bundle fonts directly in the app package for distribution:

1. **Create a Fonts folder:**
   ```bash
   mkdir -p PodcastAssistantPackage/Sources/PodcastAssistantFeature/Resources/Fonts
   ```

2. **Add your font files** (`.ttf` or `.otf`) to this folder

3. **Update Package.swift** to include resources:
   ```swift
   .target(
       name: "PodcastAssistantFeature",
       dependencies: [],
       resources: [.process("Resources")]
   )
   ```

4. **Register bundled fonts** in `ThumbnailViewModel.init()`:
   ```swift
   // Add this code to register bundled fonts on app launch
   let ttfFonts = Bundle.module.urls(forResourcesWithExtension: "ttf", subdirectory: "Fonts") ?? []
   let otfFonts = Bundle.module.urls(forResourcesWithExtension: "otf", subdirectory: "Fonts") ?? []
   for fontURL in ttfFonts + otfFonts {
       registerCustomFont(from: fontURL)
   }
   ```

5. **Rebuild the app** to include the bundled fonts

**Note:** 
- System fonts (Helvetica, Arial, Futura, etc.) are always available without any setup.
- Unlike iOS, macOS apps don't require `UIAppFonts`/`Fonts provided by application` entries in Info.plist when using runtime font registration via `CTFontManagerRegisterGraphicsFont`.
- The SPM package resources are automatically included in the app bundle, no additional build settings needed.

### Modifying Transcript Format
Edit `TranscriptConverter.swift` to support different timestamp patterns by updating the format detection logic.

### Changing Thumbnail Layout
Modify `ThumbnailGenerator.swift` to adjust:
- Episode number position
- Text styling (color, stroke, shadows)
- Padding and spacing

## Troubleshooting

### Build Issues

**Error: "Missing package product 'PodcastAssistantFeature'"**

This error means you opened the wrong file. You must open `PodcastAssistant.xcworkspace`, NOT `PodcastAssistant.xcodeproj`.

**Why?** The project uses a local Swift Package for features. The `.xcworkspace` file tells Xcode about this package. Opening just the `.xcodeproj` file will cause Xcode to fail with missing package errors.

**Fix:**
1. Close Xcode
2. Open `PodcastAssistant.xcworkspace` (the workspace file)
3. Build and run (âŒ˜R)

**Other build issues:**
- Clean build folder: Product â†’ Clean Build Folder (â‡§âŒ˜K)
- Reset package caches: File â†’ Packages â†’ Reset Package Caches

### File Access Issues
The app is sandboxed. If you need additional file access:
1. Edit `PodcastAssistant/PodcastAssistant.entitlements`
2. Add required entitlements

### Image Loading Issues
- Ensure images are in supported formats (PNG, JPEG, TIFF, BMP)
- Check image file permissions
- Try smaller image files if memory issues occur

## License

MIT License - See [LICENSE](LICENSE) file for details

## Credits

Built with:
- SwiftUI
- AppKit
- Swift Package Manager
- Scaffolded with [XcodeBuildMCP](https://github.com/cameroncooke/XcodeBuildMCP)